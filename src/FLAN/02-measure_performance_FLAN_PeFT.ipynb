{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21bbcb7a",
   "metadata": {},
   "source": [
    "# Template for Accuracy Calculation for FLAN zero-shot and finetuned models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3247fa77",
   "metadata": {},
   "source": [
    "This script provides some functionalities to calculate accuracy scores for the results of fine-tuned and zero-shot models. Especially for zero-shot predictions, you might need to re-map the output of the model to match with the labels of the original data to calculate accurate metrics, as the output might add additional words or rephrase the output. If your task is not one of the tasks that we provide, you might need to add the mapping functions yourself by inspecting the output of your predictions (e.g. you can print all the unique combinations of output and original labels to see which categories have been created.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T11:57:32.100951389Z",
     "start_time": "2023-10-03T11:57:31.795989172Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "\n",
    "import pandas as pd \n",
    "from IPython.core.display import Markdown\n",
    "\n",
    "from label_utils import task_num_to_task_name, dataset_num_to_dataset_name, plot_count_and_normalized_confusion_matrix, \\\n",
    "    task_to_display_labels, load_train_and_eval_sets, load_dataset_task_prompt_mappings, map_label_to_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d741d928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37cb94a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_outputs_task_1(output):\n",
    "    if re.search(r'^(answer:){0,1}(\\s)*a(\\s)*$|(a(\\.|:|\\)))|(\\s|^|\\')relev(a|e)nt|aelevant', output.lower().strip()):\n",
    "        return 'A'\n",
    "    elif re.search(r'^(answer:){0,1}(\\s)*b(\\s)*$|b(\\.|:|\\))|not relevant|irrelevant|ielevant|\\s+b$|brrelevant', output.lower().strip()):\n",
    "        return 'B'\n",
    "    elif output == np.nan or output == 'nan':\n",
    "        return \"\"\n",
    "    else:\n",
    "        print(f'Weird value: {output.lower().strip()}')\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def map_outputs_task_2(output):\n",
    "    if re.search(r'^(answer:){0,1}(\\s)*a(\\s)*$|a(\\.|:|\\))|challnge|problem|\\bpro\\b|blem', output.lower().strip()):\n",
    "        return 'A'\n",
    "    elif re.search(r'^(answer:){0,1}(\\s)*b(\\s)*$|b(\\.|:|\\))|solution|\\blution\\b', output.lower().strip()):\n",
    "        return 'B'\n",
    "    elif re.search(r'^(answer:){0,1}(\\s)*c(\\s)*$|c(\\.|:|\\))|neither|neutral|(\\s)+c$', output.lower().strip()):\n",
    "        return 'C'\n",
    "    elif output == np.nan or output == 'nan':\n",
    "        return \"\"\n",
    "    else:\n",
    "        print(f'Weird value: {output.lower().strip()}')\n",
    "        return \"np.nan\"\n",
    "\n",
    "\n",
    "def map_outputs_task_3(output):\n",
    "    if re.search(r'^(answer:){0,1}(\\s)*a(\\s)*$|a(\\.|:|\\))|economic|economy|aconomy', output.lower().strip()):\n",
    "        return 'A'\n",
    "\n",
    "    elif re.search(r'^(answer:){0,1}(\\s)*b(\\s)*$|b(\\.|:|\\))|morality|rality', output.lower().strip()):\n",
    "        return 'B'\n",
    "\n",
    "    elif re.search(r'^(answer:){0,1}(\\s)*c(\\s)*$|c(\\.|:|\\))|fairness and equality|irness and equality', output.lower().strip()):\n",
    "        return 'C'\n",
    "\n",
    "    elif re.search(r'^(answer:){0,1}(\\s)*d(\\s)*$|d(\\.|:|\\))|policy prescription and evaluation|prescription and evaluation|licy prescription',\n",
    "                   output.lower().strip()):\n",
    "        return 'D'\n",
    "\n",
    "    elif re.search(r'^(answer:){0,1}(\\s)*e(\\s)*$|e(\\.|:|\\))|law and order|crime and justice|law enforcement|w and order', output.lower().strip()):\n",
    "        return 'E'\n",
    "\n",
    "    elif re.search(r'^(answer:){0,1}(\\s)*f(\\s)*$|f(\\.|:|\\))|security and defense|curity and defense', output.lower().strip()):\n",
    "        return 'F'\n",
    "\n",
    "    elif re.search(r'^(answer:){0,1}(\\s)*g(\\s)*$|g(\\.|:|\\))|health and safety|alth and safety', output.lower().strip()):\n",
    "        return 'G'\n",
    "\n",
    "    elif re.search(r'^(answer:){0,1}(\\s)*h(\\s)*$|h(\\.|:|\\))|quality of life|ality of life', output.lower().strip()):\n",
    "        return 'H'\n",
    "\n",
    "    elif re.search(r'^(answer:){0,1}(\\s)*i(\\s)*$|i(\\.|:|\\))|political|litical', output.lower().strip()):\n",
    "        return 'I'\n",
    "\n",
    "    elif re.search(r'^(answer:){0,1}(\\s)*j(\\s)*$|j(\\.|:|\\))|external (regulation|region) and reputation|external regulation|regulation and reputation', output.lower().strip()):\n",
    "        return 'J'\n",
    "\n",
    "    elif re.search(\n",
    "            r'^(answer:){0,1}(\\s)*k(\\s)*$|(k|n|w)(\\.|:|\\))|other|climate change|leadership and executive responsibility|'\n",
    "            r'expansion of service opportunities|access to higher ed|potential',\n",
    "            output.lower().strip()):\n",
    "        return 'K'\n",
    "\n",
    "    elif output == np.nan or output == 'nan':\n",
    "        return \"\"\n",
    "\n",
    "    else:\n",
    "        print(f'Weird value: {output.lower().strip()}')\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def map_outputs_task_4(output):\n",
    "    if re.search(r'^(answer:){0,1}(\\s)*a(\\s)*$|a(\\.|:|\\))|positive|postive stance|in favor|in advantage of|aast|a favor of a', output.lower().strip()):\n",
    "        return 'A'\n",
    "\n",
    "    elif re.search(r'^(answer:){0,1}(\\s)*b(\\s)*$|b(\\.|:|\\))|negative|negative stance|against|aggainst|bast', output.lower().strip()):\n",
    "        return 'B'\n",
    "\n",
    "    elif re.search(r'^(answer:){0,1}(\\s)*c(\\s)*$|c(\\.|:|\\))|neutral|neutral stance|cast', output.lower().strip()):\n",
    "        return 'C'\n",
    "\n",
    "    elif output == np.nan or output == 'nan':\n",
    "        return \"\"\n",
    "\n",
    "    else:\n",
    "        print(f'Weird value: {output.lower().strip()}')\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def map_outputs_task_5(output):\n",
    "    if re.search(r'^(answer:){0,1}(\\s)*a(\\s)*$|a(\\.|:|\\))|section 230|230', output.lower().strip()):\n",
    "        return 'A'\n",
    "\n",
    "    elif re.search(r'^(answer:){0,1}(\\s)*b(\\s)*$|b(\\.|:|\\))|trump ban|ban donald trump|ban(ning){0,1} trump|tr ban', output.lower().strip()):\n",
    "        return 'B'\n",
    "\n",
    "    elif re.search(r'^(answer:){0,1}(\\s)*c(\\s)*$|c(\\.|:|\\))|twitter support', output.lower().strip()):\n",
    "        return 'C'\n",
    "\n",
    "    elif re.search(r'^(answer:){0,1}(\\s)*d(\\s)*$|d(\\.|:|\\))|platform policies|policies', output.lower().strip()):\n",
    "        return 'D'\n",
    "\n",
    "    elif re.search(r'^(answer:){0,1}(\\s)*e(\\s)*$|e(\\.|:|\\))|complaint(s)+', output.lower().strip()):\n",
    "        return 'E'\n",
    "\n",
    "    elif re.search('^(answer:){0,1}(\\s)*f(\\s)*$|f(\\.|:|\\))|other',\n",
    "                   output.lower().strip()):\n",
    "        return 'F'\n",
    "\n",
    "    elif output == np.nan or output == 'nan':\n",
    "        return \"\"\n",
    "\n",
    "    else:\n",
    "        print(f'Weird value: {output.lower().strip()}')\n",
    "        return  \"\"\n",
    "    \n",
    "def map_outputs_task_6(output):\n",
    "     if re.search(r'^(answer:){0,1}(\\s)*a(\\s)*$|a(\\.|:|\\))|policy prescription|policy prescription and regulation|licy and regulation|alicy',\n",
    "                   output.lower().strip()):\n",
    "        return 'A'\n",
    "     \n",
    "     elif re.search(r'^(answer:){0,1}(\\s)*b(\\s)*$|b(\\.|:|\\))|morality|rality', output.lower().strip()):\n",
    "        return 'B'\n",
    "     \n",
    "     elif re.search(r'^(answer:){0,1}(\\s)*c(\\s)*$|c(\\.|:|\\))|economics|econom|onomics', output.lower().strip()):\n",
    "        return 'C'\n",
    "\n",
    "     elif re.search(r'^(answer:){0,1}(\\s)*d(\\s)*$|d(\\.|:|\\))|other', output.lower().strip()):\n",
    "        return 'D'\n",
    "\n",
    "     elif output == np.nan or output == 'nan':\n",
    "        return \"\"\n",
    "\n",
    "     else:\n",
    "        print(f'Weird value: {output.lower().strip()}')\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6ab0cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_output_completed(completion: str, task:int) -> str:\n",
    "    completion = re.sub(r'(?i)Answer|folks|Plain|River|IN', '', completion)    \n",
    "    answers = completion.strip().split(' ')\n",
    "    if task == 1:\n",
    "        return map_outputs_task_1(completion)\n",
    "    if task == 2:\n",
    "        return map_outputs_task_2(completion)\n",
    "    if task == 3:\n",
    "        return map_outputs_task_3(completion)\n",
    "    if task == 4:\n",
    "        return map_outputs_task_4(completion)\n",
    "    if task == 5:\n",
    "        return map_outputs_task_5(completion)\n",
    "    if task == 6:\n",
    "        return map_outputs_task_6(completion)\n",
    "    \n",
    "    #YOU MIGHT NEED TO ADD YOUR TASK HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c453995562819655",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T11:57:32.296779243Z",
     "start_time": "2023-10-03T11:57:31.856963406Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_task_mappings_fp = os.path.join('..', '..', 'dataset_task_mappings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9139db12b6e3f8e5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a27180035560ee2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T11:57:32.297921731Z",
     "start_time": "2023-10-03T11:57:31.857458420Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_fp = glob.glob(os.path.join('..', '..', 'predictions',  'google_flan-t5-xl__w_generate', 'google_flan-t5-xl_*.csv'))\n",
    "predictions_fp = sorted(predictions_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f5771a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbb7785b19d8bf1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-03T12:05:07.264593304Z",
     "start_time": "2023-10-03T12:03:55.766727279Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(prediction_fp)\n",
    "\n",
    "# Get the expected labelset\n",
    "dataset_idx, dataset_task_mappings = load_dataset_task_prompt_mappings(\n",
    "    dataset_num=ds_num, task_num=task_num, dataset_task_mappings_fp=dataset_task_mappings_fp)\n",
    "label_column = dataset_task_mappings.loc[dataset_idx, \"label_column\"]\n",
    "labelset = dataset_task_mappings.loc[dataset_idx, \"labelset\"].split(\",\")\n",
    "labelset = [label.strip() for label in labelset]\n",
    "labelset_full_description = dataset_task_mappings.loc[dataset_idx, \"labelset_fullword\"].split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27982118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "y_pred = df.prediction_ds.map(lambda x: process_output_completed(x, task_num))\n",
    "#assert df['pred_label'].map(lambda pred: pred not in labelset).sum() == 0, 'Prediction not in expected labelset'\n",
    "\n",
    "# Get ground truth in same format\n",
    "y_true = df[label_column].map(lambda label: map_label_to_completion(\n",
    "    label=label, task_num=task_num, full_label=False))\n",
    "assert y_true.map(lambda pred: pred not in labelset).sum() == 0, 'Ground truth not in expected labelset'\n",
    "    \n",
    "# Get accuracy\n",
    "labels = labelset\n",
    "display_labels = labelset_full_description\n",
    "cm_plot, classification_report, metrics = plot_count_and_normalized_confusion_matrix(\n",
    "    y_true, y_pred, display_labels, labels, xticks_rotation='horizontal')\n",
    "\n",
    "# Get accuracy\n",
    "accuracy_summary_list.append({\n",
    "    'exp_name': os.path.basename(prediction_fp),\n",
    "    'dataset': ds_num,\n",
    "    'task': task_num,\n",
    "    'sample_size': sample_size,\n",
    "    'accuracy': metrics['accuracy'],\n",
    "    'f1-macro': metrics['f1'],\n",
    "    'precision': metrics['precision'],\n",
    "    'recall': metrics['recall']\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
